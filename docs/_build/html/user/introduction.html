

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>介绍 &mdash; Spinning Up  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/openai_icon.ico"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/modify.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="深度强化学习Spinning Up项目" href="../index.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/spinning-up-logo2.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">用户文档</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id3">这个项目是什么</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id6">为什么创建这个项目</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">这个项目如何服务我们的使命</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id8">代码设计的原则</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id9">支持计划</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="algorithms.html">算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="running.html">Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="saving_and_loading.html">Experiment Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">Plotting Results</a></li>
</ul>
<p class="caption"><span class="caption-text">强化学习介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spinningup/rl_intro.html">Part 1: Key Concepts in RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spinningup/rl_intro2.html">Part 2: Kinds of RL Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spinningup/rl_intro3.html">Part 3: Intro to Policy Optimization</a></li>
</ul>
<p class="caption"><span class="caption-text">资源</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spinningup/spinningup.html">Spinning Up as a Deep RL Researcher</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spinningup/keypapers.html">Key Papers in Deep RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spinningup/exercises.html">Exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spinningup/bench.html">Benchmarks for Spinning Up Implementations</a></li>
</ul>
<p class="caption"><span class="caption-text">算法文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/vpg.html">Vanilla Policy Gradient</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/trpo.html">Trust Region Policy Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/ppo.html">Proximal Policy Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/ddpg.html">Deep Deterministic Policy Gradient</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/td3.html">Twin Delayed DDPG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/sac.html">Soft Actor-Critic</a></li>
</ul>
<p class="caption"><span class="caption-text">工具文档</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../utils/logger.html">Logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/plotter.html">Plotter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/mpi.html">MPI Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/run_utils.html">Run Utils</a></li>
</ul>
<p class="caption"><span class="caption-text">其他</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../etc/acknowledgements.html">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../etc/author.html">About the Author</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Spinning Up</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>介绍</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/user/introduction.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1><a class="toc-backref" href="#id11">介绍</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="contents topic" id="id2">
<p class="topic-title first">目录</p>
<ul class="simple">
<li><a class="reference internal" href="#id1" id="id11">介绍</a><ul>
<li><a class="reference internal" href="#id3" id="id12">这个项目是什么</a></li>
<li><a class="reference internal" href="#id6" id="id13">为什么创建这个项目</a></li>
<li><a class="reference internal" href="#id7" id="id14">这个项目如何服务我们的使命</a></li>
<li><a class="reference internal" href="#id8" id="id15">代码设计的原则</a></li>
<li><a class="reference internal" href="#id9" id="id16">支持计划</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id3">
<h2><a class="toc-backref" href="#id12">这个项目是什么</a><a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>欢迎来到深度强化学习（deep Reinforement Learning）的Spinning Up项目！这是一份由OpenAI提供的教育资源，旨在让深度强化学习的学习变得更加简单。</p>
<p>强化学习，是一种通过教会智能体（agents）反复试错从而完成任务的机器学习方法。深度强化学习指的是强化学习和 <a class="reference external" href="http://ufldl.stanford.edu/tutorial/">深度学习</a> 的结合。</p>
<p>这个模块包括一系列有用的资源，包括：</p>
<ul class="simple">
<li>关于强化学习术语、算法和基础理论的简单`介绍`_</li>
<li>关于如何成为强化学习的研究人员的`文章`_</li>
<li>一个按照主题整理的重要论文`清单`_</li>
<li>以及一些用来练手的 <a href="#id17"><span class="problematic" id="id18">`项目`_</span></a></li>
</ul>
<p>Welcome to Spinning Up in Deep RL! This is an educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning (deep RL).</p>
<p>For the unfamiliar: <a href="#id19"><span class="problematic" id="id20">`reinforcement learning`_</span></a> (RL) is a machine learning approach for teaching agents how to solve tasks by trial and error. Deep RL refers to the combination of RL with <a href="#id21"><span class="problematic" id="id22">`deep learning`_</span></a>.</p>
<p>This module contains a variety of helpful resources, including:</p>
<ul class="simple">
<li>a short <a href="#id23"><span class="problematic" id="id24">`introduction`_</span></a> to RL terminology, kinds of algorithms, and basic theory,</li>
<li>an <a class="reference external" href="../spinningup/spinningup.html">essay</a> about how to grow into an RL research role,</li>
<li>a <a class="reference external" href="../spinningup/keypapers.html">curated list</a> of important papers organized by topic,</li>
<li>a well-documented <a class="reference external" href="https://github.com/openai/spinningup">code repo</a> of short, standalone implementations of key algorithms,</li>
<li>and a few <a class="reference external" href="../spinningup/exercises.html">exercises</a> to serve as warm-ups.</li>
</ul>
</div>
<div class="section" id="id6">
<h2><a class="toc-backref" href="#id13">为什么创建这个项目</a><a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>我们最常听到的问题是：</p>
<blockquote>
<div><div class="line-block">
<div class="line">如果我想为AI安全做贡献，我应该如何开始？</div>
</div>
</div></blockquote>
<p>在OpenAI，我们相信深度学习和深度强化学习会在未来的AI科技中扮演重要角色。为了确保AI的安全性，我们必须提出与此相契合的安全策略和算法。
因此我们鼓励每一个提出这个问题的人都来研究这些领域。</p>
<p>有很多帮助人们快速学习深度学习的资源，相比之下，深度强化学习显得门槛更高。首先，学生要有数学、编程和深度学习的背景。除此之外，他们需要
对于这一领域有高水准的理解：有哪些研究课题？为什么重要？哪些已经做出来了？，也需要认真的指导从而了解如何将算法的理论和代码
结合起来。</p>
<p>因为这个领域还很新，所以很难获得高水平的</p>
<p>One of the single most common questions that we hear is</p>
<blockquote>
<div><div class="line-block">
<div class="line">If I want to contribute to AI safety, how do I get started?</div>
</div>
</div></blockquote>
<p>At OpenAI, we believe that deep learning generally&#8212;and deep reinforcement learning specifically&#8212;will play central roles in the development of powerful AI technology. To ensure that AI is safe, we have to come up with safety strategies and algorithms that are compatible with this paradigm. As a result, we encourage everyone who asks this question to study these fields.</p>
<p>However, while there are many resources to help people quickly ramp up on deep learning, deep reinforcement learning is more challenging to break into. To begin with, a student of deep RL needs to have some background in math, coding, and regular deep learning. Beyond that, they need both a high-level view of the field&#8212;an awareness of what topics are studied in it, why they matter, and what&#8217;s been done already&#8212;and careful instruction on how to connect algorithm theory to algorithm code.</p>
<p>The high-level view is hard to come by because of how new the field is. There is not yet a standard deep RL textbook, so most of the knowledge is locked up in either papers or lecture series, which can take a long time to parse and digest. And learning to implement deep RL algorithms is typically painful, because either</p>
<ul class="simple">
<li>the paper that publishes an algorithm omits or inadvertently obscures key design details,</li>
<li>or widely-public implementations of an algorithm are hard to read, hiding how the code lines up with the algorithm.</li>
</ul>
<p>While fantastic repos like <a class="reference external" href="https://github.com/rll/rllab">rllab</a>, <a class="reference external" href="https://github.com/openai/baselines">Baselines</a>, and <a class="reference external" href="https://github.com/ray-project/ray/tree/master/python/ray/rllib">rllib</a> make it easier for researchers who are already in the field to make progress, they build algorithms into frameworks in ways that involve many non-obvious choices and trade-offs, which makes them hard to learn from. Consequently, the field of deep RL has a pretty high barrier to entry&#8212;for new researchers as well as practitioners and hobbyists.</p>
<p>So our package here is designed to serve as the missing middle step for people who are excited by deep RL, and would like to learn how to use it or make a contribution, but don&#8217;t have a clear sense of what to study or how to transmute algorithms into code. We&#8217;ve tried to make this as helpful a launching point as possible.</p>
<p>That said, practitioners aren&#8217;t the only people who can (or should) benefit from these materials. Solving AI safety will require people with a wide range of expertise and perspectives, and many relevant professions have no connection to engineering or computer science at all. Nonetheless, everyone involved will need to learn enough about the technology to make informed decisions, and several pieces of Spinning Up address that need.</p>
</div>
<div class="section" id="id7">
<h2><a class="toc-backref" href="#id14">这个项目如何服务我们的使命</a><a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>OpenAI&#8217;s <a class="reference external" href="https://blog.openai.com/openai-charter/">mission</a> is to ensure the safe development of AGI and the broad distribution of benefits from AI more generally. Teaching tools like Spinning Up help us make progress on both of these objectives.</p>
<p>To begin with, we move closer to broad distribution of benefits any time we help people understand what AI is and how it works. This empowers people to think critically about the many issues we anticipate will arise as AI becomes more sophisticated and important in our lives.</p>
<p>Also, critically, <a class="reference external" href="https://jobs.lever.co/openai">we need people to help</a> us work on making sure that AGI is safe. This requires a skill set which is currently in short supply because of how new the field is. We know that many people are interested in helping us, but don&#8217;t know how&#8212;here is what you should study! If you can become an expert on this material, you can make a difference on AI safety.</p>
</div>
<div class="section" id="id8">
<h2><a class="toc-backref" href="#id15">代码设计的原则</a><a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>The algorithm implementations in the Spinning Up repo are designed to be</p>
<blockquote>
<div><ul class="simple">
<li>as simple as possible while still being reasonably good,</li>
<li>and highly-consistent with each other to expose fundamental similarities between algorithms.</li>
</ul>
</div></blockquote>
<p>They are almost completely self-contained, with virtually no common code shared between them (except for logging, saving, loading, and <a class="reference external" href="https://en.wikipedia.org/wiki/Message_Passing_Interface">MPI</a> utilities), so that an interested person can study each algorithm separately without having to dig through an endless chain of dependencies to see how something is done. The implementations are patterned so that they come as close to pseudocode as possible, to minimize the gap between theory and code.</p>
<p>Importantly, they&#8217;re all structured similarly, so if you clearly understand one, jumping into the next is painless.</p>
<p>We tried to minimize the number of tricks used in each algorithm&#8217;s implementation, and minimize the differences between otherwise-similar algorithms. To give some examples of removed tricks: we omit <a class="reference external" href="https://github.com/haarnoja/sac/blob/108a4229be6f040360fcca983113df9c4ac23a6a/sac/distributions/normal.py#L69">regularization</a> terms present in the original Soft-Actor Critic code, as well as <a class="reference external" href="https://github.com/openai/baselines/blob/28aca637d0f13f4415cc5ebb778144154cff3110/baselines/run.py#L131">observation normalization</a> from all algorithms. For an example of where we&#8217;ve removed differences between algorithms: our implementations of DDPG, TD3, and SAC all follow a convention laid out in the <a class="reference external" href="https://github.com/sfujim/TD3/blob/25dfc0a6562c54ae5575fad5b8f08bc9d5c4e26c/main.py#L89">original TD3 code</a>, where all gradient descent updates are performed at the ends of episodes (instead of happening all throughout the episode).</p>
<p>All algorithms are &#8220;reasonably good&#8221; in the sense that they achieve roughly the intended performance, but don&#8217;t necessarily match the best reported results in the literature on every task. Consequently, be careful if using any of these implementations for scientific benchmarking comparisons. Details on each implementation&#8217;s specific performance level can be found on our <a class="reference external" href="../spinningup/bench.html">benchmarks</a> page.</p>
</div>
<div class="section" id="id9">
<h2><a class="toc-backref" href="#id16">支持计划</a><a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>We plan to support Spinning Up to ensure that it serves as a helpful resource for learning about deep reinforcement learning. The exact nature of long-term (multi-year) support for Spinning Up is yet to be determined, but in the short run, we commit to:</p>
<ul>
<li><p class="first">High-bandwidth support for the first three weeks after release (Nov 8, 2018 to Nov 29, 2018).</p>
<blockquote>
<div><ul class="simple">
<li>We&#8217;ll move quickly on bug-fixes, question-answering, and modifications to the docs to clear up ambiguities.</li>
<li>We&#8217;ll work hard to streamline the user experience, in order to make it as easy as possible to self-study with Spinning Up.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Approximately six months after release (in April 2019), we&#8217;ll do a serious review of the state of the package based on feedback we receive from the community, and announce any plans for future modification, including a long-term roadmap.</p>
</li>
</ul>
<p>Additionally, as discussed in the blog post, we are using Spinning Up in the curriculum for our upcoming cohorts of <a class="reference external" href="https://jobs.lever.co/openai/cf6de4ed-4afd-4ace-9273-8842c003c842">Scholars</a> and <a class="reference external" href="https://jobs.lever.co/openai/c9ba3f64-2419-4ff9-b81d-0526ae059f57">Fellows</a>. Any changes and updates we make for their benefit will immediately become public as well.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral" title="深度强化学习Spinning Up项目" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, OpenAI .

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>